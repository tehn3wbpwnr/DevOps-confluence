<!DOCTYPE html>
<html>
    <head>
        <title>DevOps / Pipeline &amp; Deployment : Pipelines</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">DevOps / Pipeline &amp; Deployment</a></span>
                            </li>
                                                    <li>
                                <span><a href="1179353439.html">DevOps / Pipeline &amp; Deployment Home</a></span>
                            </li>
                                                    <li>
                                <span><a href="Onboarding-Documents_1541537838.html">Onboarding Documents</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            DevOps / Pipeline &amp; Deployment : Pipelines
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Joshua Moore</span>, last modified by <span class='editor'> Jonathan Bezeau</span> on Apr 09, 2025
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <h2 id="Pipelines-Introduction">Introduction</h2><p>On this page we will introduce you to our pipeline a bit more in-depth, talking about the tools used, how it runs, etc. Our pipelines run on a Virtual Machine (VM) hosted on Azure. Currently it runs on a VM that is running Windows, this may change in the future. Now what does the VM actually run that handles the pipeline? Let me introduce <strong>Jenkins</strong>.</p><p><strong>What is Jenkins? </strong>Jenkins is an open-source automation server used to build, test, and deploy software. The VM runs Jenkins, which then handles running pipelines, managing builds, etc. We can use it to setup custom pipelines and workflows for projects. Our code files are located here: <a class="external-link" data-card-appearance="inline" href="https://bitbucket.org/VARLab/devops-pipeline/src/main/" rel="nofollow">https://bitbucket.org/VARLab/devops-pipeline/src/main/</a>  We use a variety of scripting types, from Python, Bash, Groovy (<a class="external-link" data-card-appearance="inline" href="https://groovy-lang.org/" rel="nofollow">https://groovy-lang.org/</a> for additional information), to just direct command line calls through pipeline.</p><p>We have 2 types of projects we currently work on at VAR Lab, <strong>Unity</strong> projects, and <strong>JavaScript</strong> projects. Since they both have different needs we then have to different major workflows we can apply to a project. These get connected to our Jenkins server by using a <strong>Web-hook</strong> that is set to trigger when certain conditions are met such as a Pull Request is made, it will send a web request to the set URL with information about the repo and pull request. Jenkins then starts running the associated script for that URL.</p><h2 id="Pipelines-HelperFiles">Helper Files</h2><p>We have a number of what we would call “Helper files” This are files that contain anything ranging from Python scripts (typically used to make web requests, taking advantage of pythons libraries), BASH scripts (typically used to handle running lots of command line commands), and Groovy scripts (These are similar to Java, and allow us to separate logic into smaller reusable methods). These allow us to separate logic from the pipeline into reusable chunks of code that can be called upon by multiple different pipelines, additionally keeping that actual pipeline script more human readable by effectively naming the functions. </p><p>Additionally Jenkins has plugin support. This can allow us to use tools such as <strong>SonarQube </strong>which is a static code analysis tool.</p><h2 id="Pipelines-UnityPipeline">Unity Pipeline</h2><p>This section will break down the steps within our Unity pipeline so you can familiarize yourself with how the pipeline stages work. First we will cover our “JenkinsFile” that is within the DLXJenkins folder of our repository of pipeline scripts.</p><h3 id="Pipelines-PrepareWorkspace">Prepare Workspace</h3><p>As the unity pipeline begins it starts with a stage called “Prepare Workspace”. Within this stage we handle the following:</p><ul><li><p>Pulling the remote branch associated with the PR.</p></li><li><p>Merging Main into the branch to ensure no conflicts.</p></li><li><p>Starting the Unity exe with the project and quitting to generate Unity files.</p></li></ul><p>As mentioned within the name, the goal of this stage is to ensure the workspace is setup and ready to run in the other stages.</p><h3 id="Pipelines-Linting">Linting</h3><p>This is the next stage within the pipeline. Its main focus is to check against our style guide which is laid out here: <a href="https://varlab-dev.atlassian.net/wiki/spaces/VAR/pages/59507580/Code+Style+Guide" data-linked-resource-id="59507580" data-linked-resource-version="15" data-linked-resource-type="page">Code Style Guide</a>  This is done using the dotnet format tool and a .editorconfig file which has rules laid out, such as public and private naming conventions (Pascal or camelCase). This calls on a bash script to run the tool, then checks for a JSON report which is then formatted into a report that is sent to bitbuckets REST API(<a class="external-link" data-card-appearance="inline" href="https://developer.atlassian.com/cloud/bitbucket/rest/api-group-reports/#api-group-reports" rel="nofollow">https://developer.atlassian.com/cloud/bitbucket/rest/api-group-reports/#api-group-reports</a> ). This allows the developers to see the information from the report directly in their Pull Request!</p><h3 id="Pipelines-EditModeTests">Edit Mode Tests</h3><p>This is the first testing stage of the unity pipeline. Unity projects often have 2 different types of tests, and that is based on if their is a need for the Unity runtime to be active, such as calling the lifecycle functions(Awake, Start, etc). Here the unity .exe is called with the appropriate flags to run the tests that exist within the project, outputting a report to a folder that is associated with this instance of the pipeline running.</p><h3 id="Pipelines-PlayModeTests">Play Mode Tests</h3><p>This is the second testing stage of the unity pipeline, and this is the test stage where the tests that involve Unity lifecycle calls (awake, start, etc) will be run. Similar to above the Unity.exe is called with the appropriate flags and the generated report is stored in the folder to associate it with this run/instance of the pipeline. This can be a common failing point within the pipeline as there are certain types of code that can cause issues running on our Jenkins server, since the pipeline runs without a display certain graphics related calls in the code can cause crashes.</p><h3 id="Pipelines-SendReports">Send Reports</h3><p>This stage is fairly self explanatory, it will send any unsent reports to either bit bucket, or copy them to our web server for storage/linking via a web link. One additional task performed is generating the code coverage report which gets a percentage of lines/methods covered by running the testing stages above.</p><h3 id="Pipelines-BuildProject">Build Project</h3><p>This stage is also fairly self explanatory. It calls the Unity.exe with the appropriate flags to trigger a WebGL build. This checks for compiler errors, and that it builds.</p><h3 id="Pipelines-WhenaPRgetsmerged">When a PR gets merged</h3><p>Additionally we have a secondary “JenkinsFileDeployment” that contains similar logic to the outlined steps above, however this one has an additional stage <strong>Deploy Build</strong>. This stage is used to copy the resulting WebGL build over to our LTI Web Server so that it can be hosted, and accessed via eConestoga. The goal of this is to ensure the newest builds are always available to test without having to manually upload them.</p><p /><h2 id="Pipelines-JavaScriptPipeline">JavaScript Pipeline</h2><p>This section will break down our other type of pipeline, which we run against projects that are more traditional web projects, using JavaScript and frameworks such as react, as they have different needs compared to a Unity project, with different tools used for running tests, and deployment. These projects will follow a similar structure to the pipeline above.</p><h3 id="Pipelines-PrepareWorkspace.1">Prepare Workspace</h3><p>Similar to the Unity Pipeline, the is a prepare workspace stage. This stage is mostly the same using git to pull the most recent commit of the branch associated with the PR that initialized the pipeline to run. However there is one additional step, We need to find which directories to test. This is because a JavaScript project may have a client and server folder within the project and they will both need to be individually handled via testing, linting, etc. This is handled via a call to a function in our groovy script that will handle search the main git directory and return all subdirectories as a comma separated string (example: “client,server”)</p><h3 id="Pipelines-InstallDependencies">Install Dependencies</h3><p>This stage is unique to the JavaScript pipeline and in here is where the subdirectories will get “npm -i”(Node Package Manager install command) called in them to install all packages required to run the code. This checks the Node version to ensure it is working, then will call “npm -i” within each subdirectory, again this calls a function in one of our groovy script files. Additionally after installing the packages we run the “npm audit” command, this lets the package manager perform a check for known vulnerable packages and then we can report back to the developers the information received from the audit.</p><h3 id="Pipelines-Linting.1">Linting</h3><p>This stage performs the linting of the code, using the eslint tool (<a class="external-link" data-card-appearance="inline" href="https://eslint.org/" rel="nofollow">https://eslint.org/</a>). This performs linting on JavaScript code. As of the time of writing this doesn’t follow a particular ruleset, just using the default settings within eslint.</p><h3 id="Pipelines-UnitTesting">Unit Testing</h3><p>This stage will perform the unit tests. These are the smallest tests to perform as there will be minimal dependencies required. This is because unit testing tests the smallest functional unit of code (often methods) so there is minimal setup required. This will use the JEST testing tool (<a class="external-link" data-card-appearance="inline" href="https://jestjs.io/" rel="nofollow">https://jestjs.io/</a> ) to both run the tests and generate a code coverage report.</p><h3 id="Pipelines-StaticAnalysis">Static Analysis</h3><p>This stage uses SonarQube to perform a static code analysis on the project. Static analysis scans the code without executing it, identifying patterns, code smells, and known vulnerabilities. This process provides valuable feedback to developers, helping to catch potential issues early and prevent bad coding practices.</p><p>In this stage, we use the SonarQube plugin to call the scanner, analyze the codebase, and wait for a response. The pipeline then checks whether the Quality Gate status is &quot;OK.&quot; If it is not, the pipeline flags the stage as failed, ensuring only high-quality code progresses further.</p><h3 id="Pipelines-BuildProject.1">Build Project</h3><p>In the normal pipeline (JenkinsFile within the JSJenkins folder) this stage is currently empty outside of returning back to the main branch, as it runs when the PR is created/updated, but no on merge which is where we would like to deploy the code. This could in future contain additional steps. Deployment details will be listed below.</p><h3 id="Pipelines-AfterPullRequestMerge">After Pull Request Merge</h3><p>Similar to the Unity pipeline, we have a separate <code>JenkinsFile</code> (<code>JenkinsFileDeployment</code>) that runs a unique script when a pull request (PR) is merged. This separation allows for different behavior when the code is finalized and merged into the main branch.</p><p>The current pipeline, as of this writing, is similar to the stages outlined earlier but includes an additional <strong>Deployment</strong> stage.</p><p>This stage:</p><ol start="1"><li><p><strong>Checks Docker Status</strong>: Verifies that Docker is running on the machine. (Docker is a platform that allows applications to run in isolated environments called containers.)</p></li><li><p><strong>Containerization</strong>: Uses the Azure Command Line Interface (CLI) and Docker to containerize the application. A Docker container is a self-contained unit of software that includes everything needed to run the application, such as libraries, dependencies, and configuration.</p></li><li><p><strong>Deployment to Azure Container Registry (ACR)</strong>:</p><ul><li><p>Packages the application (typically a client application and server application in a web project) into separate Docker containers.</p></li><li><p>Pushes these containers to the Azure Container Registry, which acts as a central repository for storing and managing container images.</p></li></ul></li><li><p><strong>Developer Usage</strong>: Once the containers are in ACR, the developer’s web servers can pull the most up-to-date containers to deploy the application in production or other environments.</p></li></ol><h2 id="Pipelines-Conclusion">Conclusion</h2><p>Now we have gone over our pipelines at a high level! We encourage you to visit the repository here: <a class="external-link" data-card-appearance="inline" href="https://bitbucket.org/VARLab/devops-pipeline/src/main/" rel="nofollow">https://bitbucket.org/VARLab/devops-pipeline/src/main/</a> to dig through the code yourself, perhaps read through the pipelines and follow along each section here (The scripts you are looking for are the 2 Files located in the <strong>DLXJenkins </strong>and <strong>JSJenkins </strong>folders). Additionally if you would like to see the output of these scripts running please visit: <a class="external-link" href="https://jenkins.vconestoga.com/" rel="nofollow">https://jenkins.vconestoga.com/</a> (Uptime is 8:30 am - 5:30pm) and review the logs of any projects build!</p><p /><p /><p />
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on May 27, 2025 13:35</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
